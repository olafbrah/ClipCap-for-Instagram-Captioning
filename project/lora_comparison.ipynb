{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LoRA Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from clip_model import CaptionModel, generate\n",
    "from dataset import InstagramDataset\n",
    "from base_finetune import fine_tune\n",
    "from transformers import GPT2Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define BLEU Score (directly from pytorch implementation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import collections\n",
    "import math\n",
    "\n",
    "def ngrams_iterator(token_list, ngrams):\n",
    "\n",
    "    def _get_ngrams(n):\n",
    "        return zip(*[token_list[i:] for i in range(n)])\n",
    "\n",
    "    for x in token_list:\n",
    "        yield x\n",
    "    for n in range(2, ngrams + 1):\n",
    "        for x in _get_ngrams(n):\n",
    "            yield \" \".join(x)\n",
    "\n",
    "def _compute_ngram_counter(tokens, max_n):\n",
    "    assert max_n > 0\n",
    "    ngrams_counter = collections.Counter(tuple(x.split(\" \")) for x in ngrams_iterator(tokens, max_n))\n",
    "\n",
    "    return ngrams_counter\n",
    "\n",
    "\n",
    "def bleu_score(candidate_corpus, references_corpus, max_n=4, weights=[0.25] * 4):\n",
    "\n",
    "\n",
    "    assert max_n == len(weights), 'Length of the \"weights\" list has be equal to max_n'\n",
    "    assert len(candidate_corpus) == len(\n",
    "        references_corpus\n",
    "    ), \"The length of candidate and reference corpus should be the same\"\n",
    "\n",
    "    clipped_counts = torch.zeros(max_n)\n",
    "    total_counts = torch.zeros(max_n)\n",
    "    weights = torch.tensor(weights)\n",
    "\n",
    "    candidate_len = 0.0\n",
    "    refs_len = 0.0\n",
    "\n",
    "    for (candidate, refs) in zip(candidate_corpus, references_corpus):\n",
    "        current_candidate_len = len(candidate)\n",
    "        candidate_len += current_candidate_len\n",
    "\n",
    "        # Get the length of the reference that's closest in length to the candidate\n",
    "        refs_len_list = [float(len(ref)) for ref in refs]\n",
    "        refs_len += min(refs_len_list, key=lambda x: abs(current_candidate_len - x))\n",
    "\n",
    "        reference_counters = _compute_ngram_counter(refs[0], max_n)\n",
    "        for ref in refs[1:]:\n",
    "            reference_counters = reference_counters | _compute_ngram_counter(ref, max_n)\n",
    "\n",
    "        candidate_counter = _compute_ngram_counter(candidate, max_n)\n",
    "\n",
    "        clipped_counter = candidate_counter & reference_counters\n",
    "\n",
    "        for ngram, count in clipped_counter.items():\n",
    "            clipped_counts[len(ngram) - 1] += count\n",
    "\n",
    "        for i in range(max_n):\n",
    "            # The number of N-grams in a `candidate` of T tokens is `T - (N - 1)`\n",
    "            total_counts[i] += max(current_candidate_len - i, 0)\n",
    "\n",
    "    if min(clipped_counts) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        pn = clipped_counts / total_counts\n",
    "        log_pn = weights * torch.log(pn)\n",
    "        score = torch.exp(sum(log_pn))\n",
    "\n",
    "        bp = math.exp(min(1 - refs_len / candidate_len, 0))\n",
    "\n",
    "        return bp * score.item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare different models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=\"cpu\", jit=False)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_data = InstagramDataset(clip_model, preprocess, tokenizer, device=device)\n",
    "loader = DataLoader(dataset=train_data, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['lora_4.pt', 'lora_16.pt', 'lora_64.pt', 'lora_256.pt']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = [\"4\", \"16\", \"64\", \"256\"]\n",
    "models = [\"lora_\" + r + \".pt\" for r in ranks]\n",
    "models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/28360\n",
      "2/28360\n",
      "3/28360\n",
      "4/28360\n",
      "5/28360\n",
      "6/28360\n",
      "7/28360\n",
      "8/28360\n",
      "9/28360\n",
      "10/28360\n",
      "11/28360\n",
      "12/28360\n",
      "13/28360\n",
      "14/28360\n",
      "15/28360\n",
      "16/28360\n",
      "17/28360\n",
      "18/28360\n",
      "19/28360\n",
      "20/28360\n",
      "21/28360\n",
      "22/28360\n",
      "23/28360\n",
      "24/28360\n",
      "25/28360\n",
      "26/28360\n",
      "27/28360\n",
      "28/28360\n",
      "29/28360\n",
      "30/28360\n",
      "31/28360\n",
      "32/28360\n",
      "33/28360\n",
      "34/28360\n",
      "35/28360\n",
      "36/28360\n",
      "37/28360\n",
      "38/28360\n",
      "39/28360\n",
      "40/28360\n",
      "41/28360\n",
      "42/28360\n",
      "43/28360\n",
      "44/28360\n",
      "45/28360\n",
      "46/28360\n",
      "47/28360\n",
      "48/28360\n",
      "49/28360\n",
      "50/28360\n",
      "51/28360\n",
      "52/28360\n",
      "53/28360\n",
      "54/28360\n",
      "55/28360\n",
      "56/28360\n",
      "57/28360\n",
      "58/28360\n",
      "59/28360\n",
      "60/28360\n",
      "61/28360\n",
      "62/28360\n",
      "63/28360\n",
      "64/28360\n",
      "65/28360\n",
      "66/28360\n",
      "67/28360\n",
      "68/28360\n",
      "69/28360\n",
      "70/28360\n",
      "71/28360\n",
      "72/28360\n",
      "73/28360\n",
      "74/28360\n",
      "75/28360\n",
      "76/28360\n",
      "77/28360\n",
      "78/28360\n",
      "79/28360\n",
      "80/28360\n",
      "81/28360\n",
      "82/28360\n",
      "83/28360\n",
      "84/28360\n",
      "85/28360\n",
      "86/28360\n",
      "87/28360\n",
      "88/28360\n",
      "89/28360\n",
      "90/28360\n",
      "91/28360\n",
      "92/28360\n",
      "93/28360\n",
      "94/28360\n",
      "95/28360\n",
      "96/28360\n",
      "97/28360\n",
      "98/28360\n",
      "99/28360\n",
      "100/28360\n",
      "101/28360\n",
      "102/28360\n",
      "103/28360\n",
      "104/28360\n",
      "105/28360\n",
      "106/28360\n",
      "107/28360\n",
      "108/28360\n",
      "109/28360\n",
      "110/28360\n",
      "111/28360\n",
      "112/28360\n",
      "113/28360\n",
      "114/28360\n",
      "115/28360\n",
      "116/28360\n",
      "117/28360\n",
      "118/28360\n",
      "119/28360\n",
      "120/28360\n",
      "121/28360\n",
      "122/28360\n",
      "123/28360\n",
      "124/28360\n",
      "125/28360\n",
      "126/28360\n",
      "127/28360\n",
      "128/28360\n",
      "129/28360\n",
      "130/28360\n",
      "131/28360\n",
      "132/28360\n",
      "133/28360\n",
      "134/28360\n",
      "135/28360\n",
      "136/28360\n",
      "137/28360\n",
      "138/28360\n",
      "139/28360\n",
      "140/28360\n",
      "141/28360\n",
      "142/28360\n",
      "143/28360\n",
      "144/28360\n",
      "145/28360\n",
      "146/28360\n",
      "147/28360\n",
      "148/28360\n",
      "149/28360\n",
      "150/28360\n",
      "151/28360\n",
      "152/28360\n",
      "153/28360\n",
      "154/28360\n",
      "155/28360\n",
      "156/28360\n",
      "157/28360\n",
      "158/28360\n",
      "159/28360\n",
      "160/28360\n",
      "161/28360\n",
      "162/28360\n",
      "163/28360\n",
      "164/28360\n",
      "165/28360\n",
      "166/28360\n",
      "167/28360\n",
      "168/28360\n",
      "169/28360\n",
      "170/28360\n",
      "171/28360\n",
      "172/28360\n",
      "173/28360\n",
      "174/28360\n",
      "175/28360\n",
      "176/28360\n",
      "177/28360\n",
      "178/28360\n",
      "179/28360\n",
      "180/28360\n",
      "181/28360\n",
      "182/28360\n",
      "183/28360\n",
      "184/28360\n",
      "185/28360\n",
      "186/28360\n",
      "187/28360\n",
      "188/28360\n",
      "189/28360\n",
      "190/28360\n",
      "191/28360\n",
      "192/28360\n",
      "193/28360\n",
      "194/28360\n",
      "195/28360\n",
      "196/28360\n",
      "197/28360\n",
      "198/28360\n",
      "199/28360\n",
      "200/28360\n",
      "201/28360\n",
      "202/28360\n",
      "203/28360\n",
      "204/28360\n",
      "205/28360\n",
      "206/28360\n",
      "207/28360\n",
      "208/28360\n",
      "209/28360\n",
      "210/28360\n",
      "211/28360\n",
      "212/28360\n",
      "213/28360\n",
      "214/28360\n",
      "215/28360\n",
      "216/28360\n",
      "217/28360\n",
      "218/28360\n",
      "219/28360\n",
      "220/28360\n",
      "221/28360\n",
      "222/28360\n",
      "223/28360\n",
      "224/28360\n",
      "225/28360\n",
      "226/28360\n",
      "227/28360\n",
      "228/28360\n",
      "229/28360\n",
      "230/28360\n",
      "231/28360\n",
      "232/28360\n",
      "233/28360\n",
      "234/28360\n",
      "235/28360\n",
      "236/28360\n",
      "237/28360\n",
      "238/28360\n",
      "239/28360\n",
      "240/28360\n",
      "241/28360\n",
      "242/28360\n",
      "243/28360\n",
      "244/28360\n",
      "245/28360\n",
      "246/28360\n",
      "247/28360\n",
      "248/28360\n",
      "249/28360\n",
      "250/28360\n",
      "251/28360\n",
      "252/28360\n",
      "253/28360\n",
      "254/28360\n",
      "255/28360\n",
      "256/28360\n",
      "257/28360\n",
      "258/28360\n",
      "259/28360\n",
      "260/28360\n",
      "261/28360\n",
      "262/28360\n",
      "263/28360\n",
      "264/28360\n",
      "265/28360\n",
      "266/28360\n",
      "267/28360\n",
      "268/28360\n",
      "269/28360\n",
      "270/28360\n",
      "271/28360\n",
      "272/28360\n",
      "273/28360\n",
      "274/28360\n",
      "275/28360\n",
      "276/28360\n",
      "277/28360\n",
      "278/28360\n",
      "279/28360\n",
      "280/28360\n",
      "281/28360\n",
      "282/28360\n",
      "283/28360\n",
      "284/28360\n",
      "285/28360\n",
      "286/28360\n",
      "287/28360\n",
      "288/28360\n",
      "289/28360\n",
      "290/28360\n",
      "291/28360\n",
      "292/28360\n",
      "293/28360\n",
      "294/28360\n",
      "295/28360\n",
      "296/28360\n",
      "297/28360\n",
      "298/28360\n",
      "299/28360\n",
      "300/28360\n",
      "301/28360\n",
      "302/28360\n",
      "303/28360\n",
      "304/28360\n",
      "305/28360\n",
      "306/28360\n",
      "307/28360\n",
      "308/28360\n",
      "309/28360\n",
      "310/28360\n",
      "311/28360\n",
      "312/28360\n",
      "313/28360\n",
      "314/28360\n",
      "315/28360\n",
      "316/28360\n",
      "317/28360\n",
      "318/28360\n",
      "319/28360\n",
      "320/28360\n",
      "321/28360\n",
      "322/28360\n",
      "323/28360\n",
      "324/28360\n",
      "325/28360\n",
      "326/28360\n",
      "327/28360\n",
      "328/28360\n",
      "329/28360\n",
      "330/28360\n",
      "331/28360\n",
      "332/28360\n",
      "333/28360\n",
      "334/28360\n",
      "335/28360\n",
      "336/28360\n",
      "337/28360\n",
      "338/28360\n",
      "339/28360\n",
      "340/28360\n",
      "341/28360\n",
      "342/28360\n",
      "343/28360\n",
      "344/28360\n",
      "345/28360\n",
      "346/28360\n",
      "347/28360\n",
      "348/28360\n",
      "349/28360\n",
      "350/28360\n",
      "351/28360\n",
      "352/28360\n",
      "353/28360\n",
      "354/28360\n",
      "355/28360\n",
      "356/28360\n",
      "357/28360\n",
      "358/28360\n",
      "359/28360\n",
      "360/28360\n",
      "361/28360\n",
      "362/28360\n",
      "363/28360\n",
      "364/28360\n",
      "365/28360\n",
      "366/28360\n",
      "367/28360\n",
      "368/28360\n",
      "369/28360\n",
      "370/28360\n",
      "371/28360\n",
      "372/28360\n",
      "373/28360\n",
      "374/28360\n",
      "375/28360\n",
      "376/28360\n",
      "377/28360\n",
      "378/28360\n",
      "379/28360\n",
      "380/28360\n",
      "381/28360\n",
      "382/28360\n",
      "383/28360\n",
      "384/28360\n",
      "385/28360\n",
      "386/28360\n",
      "387/28360\n",
      "388/28360\n",
      "389/28360\n",
      "390/28360\n",
      "391/28360\n",
      "392/28360\n",
      "393/28360\n",
      "394/28360\n",
      "395/28360\n",
      "396/28360\n",
      "397/28360\n",
      "398/28360\n",
      "399/28360\n",
      "400/28360\n",
      "401/28360\n",
      "402/28360\n",
      "403/28360\n",
      "404/28360\n",
      "405/28360\n",
      "406/28360\n",
      "407/28360\n",
      "408/28360\n",
      "409/28360\n",
      "410/28360\n",
      "411/28360\n",
      "412/28360\n",
      "413/28360\n",
      "414/28360\n",
      "415/28360\n",
      "416/28360\n",
      "417/28360\n",
      "418/28360\n",
      "419/28360\n",
      "420/28360\n",
      "421/28360\n",
      "422/28360\n",
      "423/28360\n",
      "424/28360\n",
      "425/28360\n",
      "426/28360\n",
      "427/28360\n",
      "428/28360\n",
      "429/28360\n",
      "430/28360\n",
      "431/28360\n",
      "432/28360\n",
      "433/28360\n",
      "434/28360\n",
      "435/28360\n",
      "436/28360\n",
      "437/28360\n",
      "438/28360\n",
      "439/28360\n",
      "440/28360\n",
      "441/28360\n",
      "442/28360\n",
      "443/28360\n",
      "444/28360\n",
      "445/28360\n",
      "446/28360\n",
      "447/28360\n",
      "448/28360\n",
      "449/28360\n",
      "450/28360\n",
      "451/28360\n",
      "452/28360\n",
      "453/28360\n",
      "454/28360\n",
      "455/28360\n",
      "456/28360\n",
      "457/28360\n",
      "458/28360\n",
      "459/28360\n",
      "460/28360\n",
      "461/28360\n",
      "462/28360\n",
      "463/28360\n",
      "464/28360\n",
      "465/28360\n",
      "466/28360\n",
      "467/28360\n",
      "468/28360\n",
      "469/28360\n",
      "470/28360\n",
      "471/28360\n",
      "472/28360\n",
      "473/28360\n",
      "474/28360\n",
      "475/28360\n",
      "476/28360\n",
      "477/28360\n",
      "478/28360\n",
      "479/28360\n",
      "480/28360\n",
      "481/28360\n",
      "482/28360\n",
      "483/28360\n",
      "484/28360\n",
      "485/28360\n",
      "486/28360\n",
      "487/28360\n",
      "488/28360\n",
      "489/28360\n",
      "490/28360\n",
      "491/28360\n",
      "492/28360\n",
      "493/28360\n",
      "494/28360\n",
      "495/28360\n",
      "496/28360\n",
      "497/28360\n",
      "498/28360\n",
      "499/28360\n",
      "500/28360\n",
      "501/28360\n",
      "502/28360\n",
      "503/28360\n",
      "504/28360\n",
      "505/28360\n",
      "506/28360\n",
      "507/28360\n",
      "508/28360\n",
      "509/28360\n",
      "510/28360\n",
      "511/28360\n",
      "512/28360\n",
      "513/28360\n",
      "514/28360\n",
      "515/28360\n",
      "516/28360\n",
      "517/28360\n",
      "518/28360\n",
      "519/28360\n",
      "520/28360\n",
      "521/28360\n",
      "522/28360\n",
      "523/28360\n",
      "524/28360\n",
      "525/28360\n",
      "526/28360\n",
      "527/28360\n",
      "528/28360\n"
     ]
    }
   ],
   "source": [
    "captioner = CaptionModel(10)\n",
    "captioner.load_state_dict(torch.load('state_dicts/coco_weights.pt', map_location=\"cpu\"))\n",
    "candidate, reference = [], []\n",
    "for i, (tokens, prefix, mask) in enumerate(loader):\n",
    "    num_tokens = (mask.sum() - 10).long().item()\n",
    "    reference.append(tokenizer.decode(tokens[:, :num_tokens].squeeze()).split())\n",
    "\n",
    "    prefix_embed = captioner.clip_project(prefix).reshape(1, 10, -1)\n",
    "    candidate.append(generate(captioner, tokenizer, embed=prefix_embed).split())\n",
    "    print(f\"{i+1}/{len(loader)}\")\n",
    "og_bleu = bleu_score(candidate, reference)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(og_bleu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

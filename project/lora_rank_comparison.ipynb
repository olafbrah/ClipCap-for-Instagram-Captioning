{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LoRA Rank Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['lora_4.pt', 'lora_16.pt', 'lora_64.pt', 'lora_256.pt']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = [\"4\", \"16\", \"64\", \"256\"]\n",
    "models = [\"lora_\" + r + \".pt\" for r in ranks]\n",
    "models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute BLEU Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/ezraapple/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torchtext/lib/libtorchtext.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n  Referenced from: <2FAC0325-6C57-347B-8605-DCE3D928A9D6> /Users/ezraapple/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torchtext/lib/libtorchtext.so\n  Expected in:     <37B48F2D-1990-3DD5-9E40-3D683B75F8C2> /Users/ezraapple/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torch/lib/libc10.dylib",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchtext\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ngrams_iterator\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_compute_ngram_counter\u001B[39m(tokens, max_n):\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m max_n \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torchtext/__init__.py:6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _get_torch_home\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _extension  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m      8\u001B[0m _TEXT_BUCKET \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://download.pytorch.org/models/text/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     10\u001B[0m _CACHE_DIR \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexpanduser(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(_get_torch_home(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torchtext/_extension.py:64\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001B[39;00m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;66;03m# This has to happen after the base library is loaded\u001B[39;00m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _torchtext  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m \u001B[43m_init_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torchtext/_extension.py:58\u001B[0m, in \u001B[0;36m_init_extension\u001B[0;34m()\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _mod_utils\u001B[38;5;241m.\u001B[39mis_module_available(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchtext._torchtext\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchtext C++ Extension is not found.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 58\u001B[0m \u001B[43m_load_lib\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlibtorchtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001B[39;00m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# This has to happen after the base library is loaded\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _torchtext\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torchtext/_extension.py:50\u001B[0m, in \u001B[0;36m_load_lib\u001B[0;34m(lib)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists():\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torch/_ops.py:105\u001B[0m, in \u001B[0;36mload_library\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m    101\u001B[0m if inspect.isclass(k) and issubclass(\n\u001B[1;32m    102\u001B[0m     k, torch.utils._python_dispatch.TorchDispatchMode\n\u001B[1;32m    103\u001B[0m ):\n\u001B[1;32m    104\u001B[0m     assert k not in self.python_key_mode_table\n\u001B[0;32m--> 105\u001B[0m     # TODO(voz): Should we replace setting torch._C.DispatchKey.Python entirely with setting mode keys?\n\u001B[1;32m    106\u001B[0m     self.python_key_mode_table[k] = fn\n\u001B[1;32m    107\u001B[0m     self._dispatch_cache.clear()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/ctypes/__init__.py:373\u001B[0m, in \u001B[0;36mCDLL.__init__\u001B[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001B[0m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_FuncPtr \u001B[38;5;241m=\u001B[39m _FuncPtr\n\u001B[1;32m    372\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 373\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m \u001B[43m_dlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m handle\n",
      "\u001B[0;31mOSError\u001B[0m: dlopen(/Users/ezraapple/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torchtext/lib/libtorchtext.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n  Referenced from: <2FAC0325-6C57-347B-8605-DCE3D928A9D6> /Users/ezraapple/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torchtext/lib/libtorchtext.so\n  Expected in:     <37B48F2D-1990-3DD5-9E40-3D683B75F8C2> /Users/ezraapple/opt/anaconda3/envs/clip_prefix_caption/lib/python3.8/site-packages/torch/lib/libc10.dylib"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "\n",
    "\n",
    "def _compute_ngram_counter(tokens, max_n):\n",
    "    assert max_n > 0\n",
    "    ngrams_counter = collections.Counter(tuple(x.split(\" \")) for x in ngrams_iterator(tokens, max_n))\n",
    "\n",
    "    return ngrams_counter\n",
    "\n",
    "\n",
    "def bleu_score(candidate_corpus, references_corpus, max_n=4, weights=[0.25] * 4):\n",
    "\n",
    "    assert max_n == len(weights), 'Length of the \"weights\" list has be equal to max_n'\n",
    "    assert len(candidate_corpus) == len(\n",
    "        references_corpus\n",
    "    ), \"The length of candidate and reference corpus should be the same\"\n",
    "\n",
    "    clipped_counts = torch.zeros(max_n)\n",
    "    total_counts = torch.zeros(max_n)\n",
    "    weights = torch.tensor(weights)\n",
    "\n",
    "    candidate_len = 0.0\n",
    "    refs_len = 0.0\n",
    "\n",
    "    for (candidate, refs) in zip(candidate_corpus, references_corpus):\n",
    "        current_candidate_len = len(candidate)\n",
    "        candidate_len += current_candidate_len\n",
    "\n",
    "        # Get the length of the reference that's closest in length to the candidate\n",
    "        refs_len_list = [float(len(ref)) for ref in refs]\n",
    "        refs_len += min(refs_len_list, key=lambda x: abs(current_candidate_len - x))\n",
    "\n",
    "        reference_counters = _compute_ngram_counter(refs[0], max_n)\n",
    "        for ref in refs[1:]:\n",
    "            reference_counters = reference_counters | _compute_ngram_counter(ref, max_n)\n",
    "\n",
    "        candidate_counter = _compute_ngram_counter(candidate, max_n)\n",
    "\n",
    "        clipped_counter = candidate_counter & reference_counters\n",
    "\n",
    "        for ngram, count in clipped_counter.items():\n",
    "            clipped_counts[len(ngram) - 1] += count\n",
    "\n",
    "        for i in range(max_n):\n",
    "            # The number of N-grams in a `candidate` of T tokens is `T - (N - 1)`\n",
    "            total_counts[i] += max(current_candidate_len - i, 0)\n",
    "\n",
    "    if min(clipped_counts) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        pn = clipped_counts / total_counts\n",
    "        log_pn = weights * torch.log(pn)\n",
    "        score = torch.exp(sum(log_pn))\n",
    "\n",
    "        bp = math.exp(min(1 - refs_len / candidate_len, 0))\n",
    "\n",
    "        return bp * score.item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
